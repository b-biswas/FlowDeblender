{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac026102-8715-491c-8261-3601c873f4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-17 12:22:44.284581: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /pbs/throng/lsst/users/bbiswas/miniconda3/envs/fvae_miniconda/lib/:\n",
      "2022-01-17 12:22:44.284632: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d255cd48-74d4-4d03-a478-f167985cd964",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0,'../')\n",
    "from scripts.FlowVAEnet import FlowVAEnet\n",
    "from scripts.utils import listdir_fullpath\n",
    "from scripts.utils import norm, denorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e4fc74-8b1f-4241-89de-06bd87b1cb3f",
   "metadata": {},
   "source": [
    "## Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8e54042-b8b5-4965-8b13-e59bc4cac7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of loaded image(1000, 2, 10, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "bands = [4,5,6,7,8,9]\n",
    "\n",
    "######## List of data samples\n",
    "images_dir = '/sps/lsst/users/barcelin/data/isolated_galaxies/' + '27.5/centered/'\n",
    "list_of_samples = [x for x in listdir_fullpath(os.path.join(images_dir,'training')) if x.endswith('.npy')]\n",
    "list_of_samples_val = [x for x in listdir_fullpath(os.path.join(images_dir,'validation')) if x.endswith('.npy')]\n",
    "\n",
    "# Take 1000 images from the first file.\n",
    "images = np.load(list_of_samples_val[0],  mmap_mode = 'c')[:1000]\n",
    "\n",
    "normalization_weights_path = '/sps/lsst/users/barcelin/data/blended_galaxies/' + '27.5/centered/test' \n",
    "print(\"Shape of loaded image\" + str(np.shape(images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1468edb1-c77f-41bb-8a66-3962e210e157",
   "metadata": {},
   "source": [
    "## Convernt image to linear normalization\n",
    "Note that the images were non-linearly normalized before being saved. So do denormalization first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f721fdc5-8d18-42e4-b30f-e6035781d7c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'convert_to_linear_norm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8338/3735022668.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# noisy or blended galaxies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimages_noisy_normed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_linear_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mimages_noisy_normed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_noisy_normed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# isolated central galaxies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'convert_to_linear_norm' is not defined"
     ]
    }
   ],
   "source": [
    "# noisy or blended galaxies\n",
    "images_noisy_normed = convert_to_linear_norm(images[:, 1, 4:])\n",
    "images_noisy_normed = np.transpose(images_noisy_normed, axes = (0,2,3,1))\n",
    "\n",
    "# isolated central galaxies\n",
    "images_isolated_normed = convert_to_linear_norm(images[:, 0, 4:])\n",
    "images_isolated_normed = np.transpose(images_isolated_normed, axes = (0,2,3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5716904c-7450-4be2-a12c-3cc5354588f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(images_isolated_normed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f7d5b6-20aa-4999-8dd1-65ca3cb5bb6a",
   "metadata": {},
   "source": [
    "## Load trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfb8c90-79ba-48c9-9f3e-593f6b7628ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_net = FlowVAEnet(latent_dim=32, linear_norm=True)\n",
    "flow_net.load_vae_weights(weights_path='/sps/lsst/users/bbiswas/weights/LSST/FlowDeblender/separated_architecture/vae/')\n",
    "flow_net.load_flow_weights(weights_path='/sps/lsst/users/bbiswas/weights/LSST/FlowDeblender/separated_architecture/fvae/')\n",
    "print(flow_net.vae_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a58839-33a0-4e5e-ad89-7013bbfbf96c",
   "metadata": {},
   "source": [
    "## Test if VAE works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce121aa-5a3f-4e8e-afc0-36939bba299f",
   "metadata": {},
   "source": [
    "### Looking at image reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69efb2d9-64d8-4b3e-b292-eac61de72fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vae_output_isolated = flow_net.vae_model(images_isolated_normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ce0121-f556-4076-82b3-1184acf602fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(12,4))\n",
    "\n",
    "image_num = 1\n",
    "\n",
    "im = axs[0].imshow(images_isolated_normed[image_num][:, :, 2])\n",
    "fig.colorbar(im, ax=axs[0], shrink=0.8)\n",
    "axs[0].set_title(\"original image\")\n",
    "\n",
    "im = axs[1].imshow(model_vae_output_isolated[0].mean().numpy()[image_num][ :, :, 2])\n",
    "fig.colorbar(im, ax=axs[1], shrink=0.8)\n",
    "axs[1].set_title(\"output image\")\n",
    "\n",
    "\n",
    "difference = images_isolated_normed[image_num][:, :, 2] - model_vae_output_isolated[0].mean().numpy()[image_num][ :, :, 2]\n",
    "im = axs[2].imshow(difference)\n",
    "fig.colorbar(im, ax=axs[2],shrink=0.8)\n",
    "axs[2].set_title(\"difference\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5256d3-7693-4917-a3a8-9de6ffde33f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images_noisy_normed[0][ :, :, 2])\n",
    "plt.title(\"original r band image\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f55d7f-c5fd-4377-b38e-46fe0074060d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test if flow network works\n",
    "\n",
    "The likelihood should be higher for isolated galaxies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b651cd-7218-471a-8518-cc1bd43b41cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "isolated_likelihood = flow_net.flow_model(images_isolated_normed)\n",
    "noisy_likelihood = flow_net.flow_model(images_noisy_normed)\n",
    "\n",
    "likelihood_difference=isolated_likelihood-noisy_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322e5d51-2c3f-4ce5-bab2-36591270584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(likelihood_difference.numpy(), bins=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e71726-5708-4dd8-8850-1595ac419194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fvae_miniconda",
   "language": "python",
   "name": "fvae_miniconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac026102-8715-491c-8261-3601c873f4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d255cd48-74d4-4d03-a478-f167985cd964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maddeb.FlowVAEnet import FlowVAEnet\n",
    "from maddeb.utils import listdir_fullpath\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e77a9f8-b5c9-4a50-8495-335a7f7672a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_norm_coeff = 80000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e4fc74-8b1f-4241-89de-06bd87b1cb3f",
   "metadata": {},
   "source": [
    "## Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e54042-b8b5-4965-8b13-e59bc4cac7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [4,5,6,7,8,9]\n",
    "\n",
    "######## List of data samples\n",
    "def listdir_fullpath(d):\n",
    "    return [os.path.join(d, f) for f in os.listdir(d) if not f.endswith(\"metadata.npy\")]\n",
    "\n",
    "train_path_isolated_gal = listdir_fullpath(\n",
    "    \"/sps/lsst/users/bbiswas/simulations/COSMOS_btk_isolated_train/\"\n",
    ")\n",
    "validation_path_isolated_gal = listdir_fullpath(\n",
    "    \"/sps/lsst/users/bbiswas/simulations/COSMOS_btk_isolated_validation/\"\n",
    ")\n",
    "\n",
    "# Take 1000 images from the first file.\n",
    "images = np.load(validation_path_isolated_gal[0], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1468edb1-c77f-41bb-8a66-3962e210e157",
   "metadata": {},
   "source": [
    "## Convernt image to linear normalization\n",
    "Note that the images were non-linearly normalized before being saved. So do denormalization first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c950ee-c3a9-4457-8c20-386fdbfd9fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "isolated_images = images['isolated_gal_stamps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97c3d22-d712-4435-82b7-ae1838f24733",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(12,4))\n",
    "\n",
    "image_num = 40\n",
    "\n",
    "im = axs[0].imshow(images['blended_gal_stamps'][image_num][:, :, 2])\n",
    "fig.colorbar(im, ax=axs[0], shrink=0.8)\n",
    "axs[0].set_title(\"original image\")\n",
    "\n",
    "im = axs[1].imshow(images['isolated_gal_stamps'][image_num][:, :, 2])\n",
    "fig.colorbar(im, ax=axs[1], shrink=0.8)\n",
    "axs[1].set_title(\"output image\")\n",
    "\n",
    "\n",
    "difference = images['blended_gal_stamps'][image_num][:, :, 2] - images['isolated_gal_stamps'][image_num][:, :, 2]\n",
    "im = axs[2].imshow(difference)\n",
    "fig.colorbar(im, ax=axs[2],shrink=0.8)\n",
    "axs[2].set_title(\"difference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b47b88-7b4d-4dc4-8a76-0ce7e9c71fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_isolated_normed = np.array(np.array(images['isolated_gal_stamps'].tolist()))/linear_norm_coeff\n",
    "#images_isolated_normed = np.transpose(images_isolated_normed, axes=(0, 2, 3, 1))\n",
    "\n",
    "images_blended_normed = np.array(np.array(images['blended_gal_stamps'].tolist()))/linear_norm_coeff\n",
    "#images_blended_normed = np.transpose(images_blended_normed, axes=(0, 2, 3, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f7d5b6-20aa-4999-8dd1-65ca3cb5bb6a",
   "metadata": {},
   "source": [
    "## Load trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfb8c90-79ba-48c9-9f3e-593f6b7628ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from maddeb.utils import get_data_dir_path\n",
    "\n",
    "data_dir = get_data_dir_path()\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "latent_dim = 8\n",
    "flow_net = FlowVAEnet(latent_dim=latent_dim)\n",
    "flow_net.load_flow_weights(weights_path=os.path.join(data_dir, \"cosmos8d/flow/val_loss\"))\n",
    "flow_net.load_vae_weights(weights_path=os.path.join(data_dir, \"cosmos8d/vae/val_loss\"))\n",
    "print(flow_net.vae_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a58839-33a0-4e5e-ad89-7013bbfbf96c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Section 1: Test the VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce121aa-5a3f-4e8e-afc0-36939bba299f",
   "metadata": {},
   "source": [
    "### Section 1.1 reconstructions.\n",
    "If the VAE is able to correctly reconstruct images, we can conclude that the decoder can be used as a generative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69efb2d9-64d8-4b3e-b292-eac61de72fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel('ERROR')\n",
    "model_vae_output_isolated = flow_net.vae_model(images_blended_normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ce0121-f556-4076-82b3-1184acf602fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style={\"axes.grid\": False,\n",
    "                     'axes.labelcolor': 'white',\n",
    "                     'figure.facecolor': '.15',\n",
    "                     'xtick.color': 'white',\n",
    "                     'ytick.color': 'white',\n",
    "                     'text.color': 'white',\n",
    "                     'image.cmap': 'viridis',})\n",
    "\n",
    "fig, axs = plt.subplots(10, 3, figsize=(10,30))\n",
    "for i in range(10):\n",
    "    \n",
    "    image_num = i+30\n",
    "    im = axs[i, 0].imshow(images_blended_normed[image_num][:, :, 2])\n",
    "    fig.colorbar(im, ax=axs[i, 0], shrink=0.8)\n",
    "    axs[i, 0].set_title(\"original image\")\n",
    "\n",
    "    im = axs[i, 1].imshow(model_vae_output_isolated.numpy()[image_num][ :, :, 2])\n",
    "    fig.colorbar(im, ax=axs[i, 1], shrink=0.8)\n",
    "    axs[i, 1].set_title(\"reconstructed image\")\n",
    "\n",
    "\n",
    "    difference = images_blended_normed[image_num][:, :, 2] - model_vae_output_isolated.numpy()[image_num][ :, :, 2]\n",
    "    im = axs[i, 2].imshow(difference)\n",
    "    fig.colorbar(im, ax=axs[i, 2],shrink=0.8)\n",
    "    axs[i, 2].set_title(\"difference\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7acb47d-bf77-4e84-950b-616efba2cf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "z = tfp.layers.MultivariateNormalTriL(event_size=latent_dim)(flow_net.encoder(images_isolated_normed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7debe0f3-4070-4354-aca9-5cd816ce0a5a",
   "metadata": {},
   "source": [
    "Conclusion: The reconstructions of galaxies work fairly well! <br>\n",
    "So the decoder can be used as a generative model by sampling from the latent space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1d58e1-323d-428d-ab9f-7299bd3192d8",
   "metadata": {},
   "source": [
    "### Section 1.2 Latent space distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b89ddb-d78b-4451-a1bd-9f3478cd152c",
   "metadata": {},
   "source": [
    "In this section we aim to study the latent space distribution of galaxies as learnt by the VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3778cf-5259-4d01-b60f-ddf6311a3b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load(validation_path_isolated_gal[0], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fba2f6-fac3-4681-a967-b863bcdd45de",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vars = []\n",
    "for i in range(10):\n",
    "    images_i = np.load(validation_path_isolated_gal[i], allow_pickle=True)\n",
    "    images_isolated_normed = np.array(np.array(images_i['isolated_gal_stamps'].tolist()))/linear_norm_coeff\n",
    "    #images_isolated_normed = np.transpose(images_isolated_normed, axes=(0, 2, 3, 1))\n",
    "    \n",
    "    z = tfp.layers.MultivariateNormalTriL(event_size=latent_dim)(flow_net.encoder(images_isolated_normed))\n",
    "\n",
    "    latent_vars.extend(list(z.sample().numpy()))\n",
    "latent_vars = np.array(latent_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d9e609-e3d9-426f-a671-77d764c93b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vars_list =[]\n",
    "for i in range(latent_dim):\n",
    "    latent_vars_list.append(latent_vars[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f308ae-028e-4d46-a66d-37b61fb1ec48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(latent_vars_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6889731a-0cb9-4321-89b0-07c9ecf9b3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(latent_vars_list, showfliers=False)\n",
    "plt.xlabel(\"Latent Variable\", fontsize=15)\n",
    "plt.ylabel(\"distribution\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d481cdb-e27b-4cd9-ace7-8c3e2ad9a5d5",
   "metadata": {},
   "source": [
    "The plot shows the distribution of the latent space variables as learnt by the VAE. <br>\n",
    "In the next section we will try to see if we can model this distribution using the Normalizing Flow network. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f55d7f-c5fd-4377-b38e-46fe0074060d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Section 2. Test the flow network\n",
    "\n",
    "### Section 2.1 Likelihood distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ee052c-74f9-4cb7-9775-927e804f25e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_blended_gal = listdir_fullpath(\n",
    "    \"/sps/lsst/users/bbiswas/simulations/COSMOS_btk_blended_train/\"\n",
    ")\n",
    "validation_path_blended_gal = listdir_fullpath(\n",
    "    \"/sps/lsst/users/bbiswas/simulations/COSMOS_btk_blended_validation/\"\n",
    ")\n",
    "# Take 1000 images from the first file.\n",
    "images_blended = np.load(validation_path_blended_gal[0], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d0c4db-a094-4b0c-88e1-ab44389f4883",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_isolated_normed = np.array(np.array(images_blended['isolated_gal_stamps'].tolist()))/linear_norm_coeff\n",
    "#images_isolated_normed = np.transpose(images_isolated_normed, axes=(0, 2, 3, 1))\n",
    "\n",
    "images_blended_normed = np.array(np.array(images_blended['blended_gal_stamps'].tolist()))/linear_norm_coeff\n",
    "#images_blended_normed = np.transpose(images_blended_normed, axes=(0, 2, 3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b651cd-7218-471a-8518-cc1bd43b41cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "isolated_likelihood = flow_net.flow_model(images_isolated_normed)\n",
    "noisy_likelihood = flow_net.flow_model(images_blended_normed)\n",
    "\n",
    "likelihood_difference=isolated_likelihood-noisy_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83df9326-4d13-4745-bfa8-bd94b9c099ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,5))\n",
    "plt.scatter(isolated_likelihood, noisy_likelihood)\n",
    "max_lim = max(np.amax(isolated_likelihood), np.amax(noisy_likelihood))\n",
    "min_lim = min(np.amin(isolated_likelihood), np.amin(noisy_likelihood))\n",
    "plt.xlim(-1000, max_lim+30)\n",
    "plt.ylim(-1000, max_lim+30)\n",
    "plt.plot((min_lim, max_lim+300), (min_lim, max_lim+300), ls=\"--\", c=\"r\", label=\"equal likelihood\")\n",
    "ax = plt.gca()\n",
    "ax.set_aspect('equal')\n",
    "plt.xlabel(\"Likelihood of isolated galaxies\", fontsize=12)\n",
    "plt.ylabel(\"Likelihood of noisy / blended galaxies\", fontsize=12)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322e5d51-2c3f-4ce5-bab2-36591270584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(likelihood_difference.numpy(), bins=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97c4170-6fae-4d8e-9f8a-28ba41d27fd2",
   "metadata": {},
   "source": [
    "### Section 2.2 Learnt latent space distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f475c7e-3722-4369-a995-425e3051568f",
   "metadata": {},
   "source": [
    "Finally, let's try to see the distribution of latent variables learnt by the normalizing flow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a692d9-f1ee-42e1-9890-fdab7a393a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_latent_vars = flow_net.td.sample(len(latent_vars_list[0])).numpy()\n",
    "sampled_latent_vars_list =[]\n",
    "for i in range(latent_dim):\n",
    "    sampled_latent_vars_list.append(sampled_latent_vars[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9999f725-5694-40f6-b4e3-5acd4108916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sampled_latent_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe494022-52ca-4bfd-96c3-50b91f3454af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(sampled_latent_vars_list, showfliers=True);\n",
    "plt.xlabel(\"sampled latent Variable\", fontsize=15)\n",
    "plt.ylabel(\"distribution\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0d0332-dfef-47f8-b1c3-71f8d3edb75e",
   "metadata": {},
   "source": [
    "On comparing the sampled latent space distribution with the actual distribution, we see by eye that the flow nework is able to learn the complex distribution in the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3240d160-3e0d-4775-8b69-c9b9cdd2956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_value=[]\n",
    "latent_var_num=[]\n",
    "latent_type=[]\n",
    "\n",
    "for i in range(latent_dim):\n",
    "    latent_value.extend(list(latent_vars_list[i]))\n",
    "    latent_var_num.extend([i]*len(latent_vars_list[i]))\n",
    "    latent_type.extend([\"actual\"]*len(latent_vars_list[i]))\n",
    "    \n",
    "    latent_value.extend(list(sampled_latent_vars_list[i]))\n",
    "    latent_var_num.extend([i]*len(sampled_latent_vars_list[i]))\n",
    "    latent_type.extend([\"learnt\"]*len(sampled_latent_vars_list[i]))\n",
    "    \n",
    "df_plot ={\"latent_value\": latent_value, \"latent_var_num\":latent_var_num, \"latent_type\":latent_type}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe7b9a5-1c87-4b89-b544-f7f975b94dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_plot = pd.DataFrame(df_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e748757-30c1-414d-832e-939af274521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb54916-66b6-4235-bb34-1cb8f33f8ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf71958-b4de-4696-aaf9-5f757620d6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style={'text.color': 'black'})\n",
    "f, ax = plt.subplots(figsize=(8, 4))\n",
    "ax = sns.violinplot(x=\"latent_var_num\", y=\"latent_value\", hue=\"latent_type\",\n",
    "                    data=df_plot, palette=\"muted\", cut=2, split=True, scale=\"width\", scale_hue=False)\n",
    "ax.set_ylim(-10,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a200df1-c47b-47a9-8212-2a7ef897b6f6",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daa6826-61db-47f3-8dcf-1edb1390084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_num = 30\n",
    "im = plt.imshow(images_blended_normed[image_num][:, :, 2]);\n",
    "ax=plt.gca()\n",
    "plt.colorbar(im, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0335bc7c-10de-4e9e-a1e9-d2c7264a5450",
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped = np.flip(images_blended_normed, axis=1)\n",
    "plt.imshow(flipped[30, :, :, 2])\n",
    "ax=plt.gca()\n",
    "plt.colorbar(im, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c6052b-4705-45e4-93ef-f8d6e6418b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped = np.flip(images_blended_normed, axis=2)\n",
    "plt.imshow(flipped[30, :, :, 2])\n",
    "ax=plt.gca()\n",
    "plt.colorbar(im, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4fba6b-ddf0-48ef-beb4-a57ad1520960",
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped = np.flip(np.flip(images_blended_normed, axis=1), axis=2)\n",
    "plt.imshow(flipped[30, :, :, 2])\n",
    "ax=plt.gca()\n",
    "plt.colorbar(im, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94130ff4-367f-47a4-9f55-2e07fa9c77e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba240b98-04cc-4aa1-9213-9384c0e3258d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "madness",
   "language": "python",
   "name": "madness"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
